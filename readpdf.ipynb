{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    }
   ],
   "source": [
    "# Uploading and loading Pdf file. Reference: https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html\n",
    "pdf_file = UnstructuredPDFLoader(file_path=\"path to file\") # Replace \"path to file\" with pdf file location at your local machine\n",
    "content = pdf_file.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the file into chunks. Reference: https://python.langchain.com/en/latest/reference/modules/text_splitter.html\n",
    "\n",
    "file_chunks = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text_chunks = file_chunks.split_documents(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"your_openai_key\" # Replace \"your_openai_key\" with ChatGPT key\n",
    "PINECONE_API_KEY = \"your_pinecone_api\" # Replace \"your_pinecone_api\" with ChatGPT key\n",
    "PINECONE_API_ENV = \"your_pinecone_env\" # Replace \"your_pinecone_env\" with ChatGPT key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embeddings for semantic search. Reference: https://python.langchain.com/en/latest/modules/models/text_embedding/examples/openai.html\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initializing pinecone. Reference: https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_API_ENV\n",
    ")\n",
    "index_name = \"Write pinecone index name\" # Replace \"Write pinecone index name\" with Pinecone index name\n",
    "texts = [text.page_content for text in text_chunks]\n",
    "# Wrapper on raw documents. Reference: https://python.langchain.com/en/latest/reference/modules/vectorstore.html\n",
    "docsearch = Pinecone.from_texts(texts, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interacting with OpenAI via API. Reference: https://python.langchain.com/en/latest/modules/models/llms/integrations/openai.html\n",
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "# starting a question answering chain. Reference: https://python.langchain.com/en/latest/use_cases/question_answering.html\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Query\n",
    "query = input(\"Write your query\")\n",
    "# Return pinecone documents most similar to query. Reference: https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The IEEE definition of software engineering is \"the application of a systematic, disciplined, quantifiable approach to the development, operation, and maintenance of software; that is, the application of engineering to software.\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
